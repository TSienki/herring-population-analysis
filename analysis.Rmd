---
title: "Projekt z analizy danych - analiza długości śledzia oceanicznego wyławianego w Europie."
author: Tomasz Sienkiewicz, Jakub Zdanowski
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
---

# Podsumowanie analizy
Celem analizy było określenie głównych przyczyn stopniowego zmniejszania się długości śledzi oceanicznych wyławianych w Europie. Analiza doprowadziła do wniosków, że istotny wpływ na długość miała temperatura przy powierzchni wody i to ona mogła doprowadzić do zmian długości. Duży wpływ na długość śledzia miały również wartości związane z dostępnością planktonu, co jest logiczne gdyż plankton jest pożywieniem dla śledzi. Wszystkie te wartości mogą jednak być związane z oscylacją północnoatlantycką, która jest zjawiskiem meteorologicznym i może mieć związek z temperaturą wody przy powierzchni i poprzez cyrkulację wody oceanicznej z dostępnością planktonu. Wartość ta jest przeciwnie skorelowana z długością, jednakże żaden regresor nie uznał jej za istotną. W danych brakuje informacji o roku pomiaru co utrudnia analizę, jednakże można ją wyłuskać z atrybutów rocznego narybku i rocznego natężenia połowów w rejonie. 

# Wprowadzenie
### Opis problemu
Celem projektu jest określenie głównych przyczyn stopniowego zmniejszania się długości śledzi oceanicznych wyławionych w Europie.

### Opis danych 
Zbiór danych do analizy składa się z pomiarów śledzi i warunków w jakich żyją z ostatnich 60 lat. Dane były pobierane z połowów komercyjnych jednostek. W ramach połowu jednej jednostki losowo wybierano od 50 do 100 sztuk trzyletnich śledzi.

### Opis zmiennych: 

Wszystkie dane, są danymi liczbowymi, nie występują żadne dane kategoryczne.

* __<span style="color:red">length</span>__: długość złowionego śledzia [cm];
* __cfin1__: dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 1];
* __cfin2__: dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 2];
* __chel1__: dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 1];
* __chel2__: dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 2];
* __lcop1__: dostępność planktonu [zagęszczenie widłonogów gat. 1];
* __lcop2__: dostępność planktonu [zagęszczenie widłonogów gat. 2];
* __fbar__: natężenie połowów w regionie [ułamek pozostawionego narybku];
* __recr__: roczny narybek [liczba śledzi];
* __cumf__: łączne roczne natężenie połowów w regionie [ułamek pozostawionego narybku];
* __totaln__: łączna liczba ryb złowionych w ramach połowu [liczba śledzi];
* __sst__: temperatura przy powierzchni wody [°C];
* __sal__: poziom zasolenia wody [Knudsen ppt];
* __xmonth__: miesiąc połowu [numer miesiąca];
* __nao__: oscylacja północnoatlantycka [mb].

### Inicjalizacja środowiska 

```{r results='hide', message=FALSE}
library(dplyr)
library(ggplot2)
library(GGally) # ggpairplot
library(DT)
library(mice) # for missing data
library(ggpubr) # ggarange
library(corrplot) # ggarange
library(plotly)
library(caret)
library(gbm)
library(doMC)

columns_names <- c("length" = "długość złowionego śledzia [cm]",
  "cfin1" = "dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 1]",
  "cfin2" = "dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 2]",
  "chel1" = "dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 1]",
  "chel2" = "dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 2]",
  "lcop1" = "dostępność planktonu [zagęszczenie widłonogów gat. 1]",
  "lcop2" = "dostępność planktonu [zagęszczenie widłonogów gat. 2]",
  "fbar" = "natężenie połowów w regionie [ułamek pozostawionego narybku]",
  "recr" = "roczny narybek [liczba śledzi]",
  "cumf" = "łączne roczne natężenie połowów w regionie [ułamek pozostawionego narybku]",
  "totaln" = "łączna liczba ryb złowionych w ramach połowu [liczba śledzi]",
  "sst" = "temperatura przy powierzchni wody [°C]",
  "sal"  = "poziom zasolenia wody [Knudsen ppt]",
  "xmonth" = "miesiąc połowu [numer miesiąca]",
  "nao" = "oscylacja północnoatlantycka [mb]" )

prettyTable <- function(table_df, round_columns=numeric(), round_digits=2) {
    DT::datatable(table_df, style="bootstrap", filter = "top", rownames = FALSE, extensions = "Buttons", options = list(dom = 'Bfrtip', buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))) %>%
    formatRound(round_columns, round_digits)
}
```



# Analiza

### Wczytanie i wstepne oczyszczenie danych

Pierwszym krokiem jest wczytanie danych oraz bliższe przyjżenie się im. Ponieważ w pliku csv brakujące rekordy zapisane są jako "?" trzeba je poprawnie wczytać.Brakujące dane występują w kolumnach cfin1, cfin2, chel1, chel2, lcop1, lcop2 i lsst. 
Jako że kolumna x to po prostu numer pomiaru, nie będzie nam potrzebna.

```{r}
set.seed(23)
data <- read.csv("sledzie.csv", na.strings = c("?"))
lapply(data, function(x) any(is.na(x)))
data <- subset(data, select = -c(X))

summary(data)
paste0("Ilość badanych przypadków: ", nrow(data), ", ilość zmiennych: ", ncol(data))
head(data, 10)
```
W celu poradzenia sobie z brakującymi danymi zostaje wykorzystana metoda MICE (Multivariate Imputation via Chained Equations). Metoda ta pozwala na pozbycie się brakujących danych z utrzymaniem podobnego rozkład

```{r mice-chunk, cache=TRUE}
plot_histograms <- function(data, columns=NULL, ncol=1, nrow=1, createName=function(x) x, bins=30){
  if(is.null(columns)){
    columns <- names(data)
  } 
  
  i <- 1
  plots <- list()
  for (column_name in columns){
    p <- ggplot(data, aes_string(x = column_name)) + 
      geom_histogram(color="black", fill="orange", bins=bins) +
      # geom_density() +
      ggtitle(createName(column_name)) + 
      ylab("Liczba obserwacji")
    plots[[i]] <- p
    i <- i + 1
  }
  figure <- ggarrange(plotlist = plots, ncol = ncol, nrow = nrow)
  figure
}


  

missing_data_columns <- c("cfin1", "cfin2", "chel1", "chel2", "lcop1", "lcop2", "sst")
# plot_histograms(data, columns = missing_data_columns, createName = function(x) paste0("Histogram ", x, " przed pozbyciem się brakujących danych"), nrow=2)
# mice_plot <- aggr(data, col=c('navyblue','yellow'),
#                     numbers=TRUE, sortVars=TRUE,
#                     labels=names(data), cex.axis=.7,
#                     gap=3, ylab=c("Missing data","Pattern"))
completed_data <- data %>%
  mice(m=3,  method = 'cart', seed = 63) %>%
  complete(2)
# plot_histograms(completed_data, columns = missing_data_columns, createName = function(x) paste0("Histogram ", x, " po pozbyciu się brakujących danych"), nrow=2)

```

### Eksploracja danych 

Podsumowanie danych
```{r}
summary(completed_data)
```

Histogramy wartości atrybutów w zbiorze danych 
Jak można zauwyć wartości długości śledzia przyjmują rozkład normalny z średnią na poziomie 25.3 cm i przyjmuje wartości w granicach 19-32.5cm. 
```{r}
plot_histograms(completed_data, createName = function(x) paste0("Histogram - ", columns_names[x]), nrow=1, bins=40)


```

Poniżej została przedstawiona korelacja pomiędzy atrybutami.
Można zauważyć, że występuje wysoka korelacja pomiędzy parami atrybutów chel1-lcop1, chel2-lcop2 oraz fbar-cumf. Korelacja może występować, ponieważ, dwie pierwsze pary związane są z dostępnością zaś ostatnia para korelacji może występować, ponieważ obydwa atrybuty związane są z natężeniem popłowu w regionie. Można te pary zredukować, aby przeciwdziałać klątwie wielowymiarowości - jednakże tutaj zostaną one zostawione bez zmian. 

```{r}
corrplot(cor(completed_data), type = "upper",  tl.col = "black", tl.srt = 45, method="number")

ggplot(completed_data, aes(x=chel1, y=lcop1)) + 
  geom_point() + 
  geom_smooth(method=lm) +
  ggtitle("Zależność pomiędzy atrybutem chel1 i lcop1")

linear_model_1 <- lm(chel1 ~ lcop1, data = completed_data)


ggplot(completed_data, aes(x=chel2, y=lcop2)) + 
  geom_point() + 
  geom_smooth(method=lm) +
  ggtitle("Zależność pomiędzy atrybutem chel2 i lcop2")
linear_model_2 <- lm(chel2 ~ lcop2, data = completed_data)


ggplot(completed_data, aes(x=fbar, y=cumf)) + 
  geom_point() + 
  geom_smooth(method=lm) +
  ggtitle("Zależność pomiędzy atrybutem fbar i cumf")
linear_model_3 <- lm(fbar ~ cumf, data = completed_data)

```

Poniżej przedstawiona została analiza długości śledzia na przestrzeni czasu. Jednakże czas nie był przedstawiony jawnie, ale wiadomo, że dane są ustawione chronologicznie dzięki czemu, zbiór można podzielić i na każdym z podziałów policzyć średnią. Można zauważyć, że na początku długość śledzia na przestrzeni czasu wzrastała od średniej wielkości w oklicach 24.5 cm do wielkości wielkości przekraczającej 27cm. Jednakże później trend się odwrócił i ostatecznie na sam koniec średnia ta była poniżej 24 cm. 
```{r}
aggregate_data <- function(data, cases_per_aggregate){
  new_aggregated_data <- aggregate(data, 
                        list(rep(1:(nrow(data)%/%cases_per_aggregate+1), each=cases_per_aggregate, len=nrow(data))),
                        mean) # Try using mean without outliners
  new_aggregated_data$time_period = c(1:nrow(new_aggregated_data))
  new_aggregated_data
}


aggregated_data <- aggregate_data(completed_data, 200)
ggplot(aggregated_data, aes(time_period, length)) +
  geom_point() + 
  geom_smooth() +
  ggtitle("Wykres zmiany długości śledzia na przestrzeni czasu") +
  ylab("Długość śledzia") +
  xlab("Przedział czasowy")

```

```{r}
plot_ly(data = aggregated_data, x = ~time_period, y = ~length,
            text = ~paste("Length: ", length)) 
# %>% layout(
#               scene = list(
#                  xaxis = list(title = "Przedział czasowy"),
#                  yaxis = list(title = "Długość śledzia")
#               )
#             )
```
# Regresor

```{r}

train_index <- createDataPartition(completed_data$length, p = .7, 
                                  list = FALSE, 
                                  times = 1)
training <- completed_data[ train_index,]
testing  <- completed_data[-train_index,]

r_squared <- function (x, y) cor(x, y) ^ 2

registerDoMC(cores=8)

ctrl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3
  )

evaluate_model <- function(model, test_data) {
  print(model)
  plot <- ggplot(varImp(model))
  print(varImp(model))
  print(plot)
  predicted <- predict(model, newdata = test_data)
  rmse_ <- RMSE(predicted, test_data$length)
  rsquared <- r_squared(predicted, test_data$length)
  print(paste0("RMSE na zbiorze testowym: ", rmse_, " R-Squared na zbiorze testowym ", rsquared))
  c(rmse_, rsquared)
}

```

## Elastic Net


```{r glmnet-chunk, cache=TRUE}
modelLookup(model='glmnet')
glmnet_grid = expand.grid(
  alpha = 0:1,
  lambda = seq(0.0001, 1, length = 100)
)

set.seed(23)

glmnet <- train(length ~ .,
             data = training,
             method = "glmnet",
             preProc = c("center", "scale"),
             metric = "RMSE",
             trControl = ctrl,
             tuneGrid = glmnet_grid,
             importance=TRUE)

glmnet_metrics = evaluate_model(glmnet, testing)
```


## Random Forest


```{r rf-chunk, cache=TRUE}
set.seed(23)
modelLookup(model='rf')

rf_grid <- expand.grid(mtry=c(2, 3, 4, 5, 6, 7, 8, 9, 11, 14))

random_forest <- train(length ~ .,
             data = training,
             method = "rf",
             preProc = c("center", "scale"),
             metric = "RMSE",
             trControl = ctrl,
             tuneGrid = rf_grid,
             ntree = 10,
             importance=TRUE)

rf_metrics = evaluate_model(random_forest, testing)

```



## Gradient Boosting Regressor

Podane parametry zostały znaliezone wcześniej wykorzystując grid search, jednakż trwało to bardzo długo i żeby nie ponawiać tych obliczeń parametry zostały tu wpisane na sztywno.

```{r gbm-chunk, cache=TRUE}

modelLookup(model='gbm')

gbm_grid <- expand.grid(
  n.trees=c(10,20,50,100,500,1000),
  shrinkage=c(0.01,0.05,0.1,0.5),
  n.minobsinnode = c(3,5,10),
  interaction.depth=c(1,5,10)
  )

set.seed(23)

params <- data.frame( shrinkage = 0.1, n.trees = 1000, interaction.depth = 10, n.minobsinnode = 10)


gbm <- train(length ~ ., 
             data = training, 
             method = "gbm", 
             metric = "RMSE",
             tuneGrid = params,
             # trControl = ctrl,
             # tuneGrid = gbm_grid,
             preProc = c("center", "scale"),
             verbose = FALSE)

gbm_metrics = evaluate_model(gbm, testing)
ggplot(varImp(gbm))
```

## Podsumowanie regresorów 

Jak można zauważyć poniżej najlepszymi modelami okazały się modele oparte na algorytmach Gradient Boosting i Random Forest. Jest nieznaczna różnica pomiędzy tymi algorytmami. Nieco gorzej sprawdza się algorytm random forest. Najgorzej i poniżej oczekiwań działa algorytm Elastic Net, co może być związane z wykorzystaniem regresji liniowej wewnątrz algorytmu. 

```{r}
metrics <- data.frame(
   regressor = c("Elastic Net","Random Forest","Gradient Boosting Regressor"),
   rmse = c(glmnet_metrics[1], rf_metrics[1], gbm_metrics[1]), 
   rsquared = c(glmnet_metrics[2], rf_metrics[2], gbm_metrics[2])
)

metrics
```

Analizując istotność danych dla Elastic Net trzema najistotniejszymi atrybutami są fbar, cumf i sst, a najmniej istotnymi chel2, xmonth i sal. Dla algorytmu random forest najistotniejszymi  były xmonth, chel1 i cfin2, a najmniej istotne cumf, sal i mao. 
Najważniejszymi atrybutami dla algorytmu Gradient Boosting były sst, recr i xmonth, a najmniej istotnymi chel1, fbar i sal (wszystkie bardzo niskie).

Można się spodziewać, że atrybut xmonth jest skorelowany z długością (jest to najistotniejszy atrybut dla Random Forest i trzeci najbardziej istotny dla Gradient Boosting). Jednakże nie oznacza to, że jest to wynik wieloletniego trendu, a może na przykład wynikać z wahań związanych z okresami godowymi lub okresami zwiększonego połowu.  
Można zauważyć dużą istotność atrybutu sst - najistotniejszy atrybut dla Gradient Boosting, trzeci najbardziej istotny dla Elastic Net. Na wykresie poniżej można zauważyć że średnia długość śledzia jest przeciwnie skorelowana z temperaturą wody przy powierzchni. Może to świadczyć, że jest to powód zmian długości śledzi na przestrzeni lat.



```{r}
ggplot(aggregated_data, aes(x = time_period)) +
  geom_point(aes(y = sst * 2, colour = "sst")) +
  geom_point(aes(y = length, colour = "length")) +
  scale_y_continuous(sec.axis = sec_axis(~.*0.5, name = columns_names["lcop1"])) + 
  scale_colour_manual(values = c("blue", "red")) +
  labs(y = columns_names["length"], x = "Przedział czasowy", colour = "Wartości") +
  theme(legend.position = c(0.25, 0.1)) + 
  ggtitle("Długość śledzia wraz z temperaturą pod powierzchnią wody na przestrzeni lat")
```
Mimo występowania korelacji pomiędzy długością, a oscylacją północnoatlantycką, żaden z regresorów nie uznawał tego atrybutu za istotny. 
Mniejszą zależność widać w przypadku lcop2 (i chel2). 

```{r}
ggplot(aggregate_data(completed_data, 1000), aes(x = time_period)) +
  geom_line(aes(y = nao + 25, colour = "nao")) +
  geom_line(aes(y = length, colour = "length")) +
  scale_y_continuous(sec.axis = sec_axis(~.-25, name = columns_names["nao"])) +
  scale_colour_manual(values = c("blue", "red")) +
  labs(y = columns_names["length"], x = "Przedział czasowy", colour = "Wartości") +
  theme(legend.position = c(0.25, 0.1)) +
  ggtitle("Długość śledzia wraz z oscylacja północnoatlantycką na przestrzeni lat")
```

Często istotnym atrybutem jest atrybut lcop1 (jak i chel1 poprzez korelacje) czyli dostępność planktonu [zagęszczenie widłonogów gat. 1]. Można zauważyć podobny trend zmian tych wartości do trendu zmian wartości długości. Dodatkowo jest on skorelowany z oscylacją północnoatlantycką, przez co ten drugi atrybut może nie występować w istotnych atrybutach.  
```{r}
ggplot(aggregate_data(completed_data, 1000), aes(x = time_period)) +
  geom_line(aes(y = lcop1 / 10 + 25 , colour = "lcop1")) +
  geom_line(aes(y = length, colour = "length")) +
  scale_y_continuous(sec.axis = sec_axis(~ (.- 25) * 10, name = columns_names["lcop1"])) +
  scale_colour_manual(values = c("blue", "red")) +
  labs(y = columns_names["length"], x = "Przedział czasowy", colour = "Wartości") +
  theme(legend.position = c(0.25, 0.1)) +
  ggtitle("Długość śledzia wraz z zagęszczeniem widłogonów gat. 1 na przestrzeni lat")

ggplot(aggregate_data(completed_data, 1000), aes(x = time_period)) +
  geom_line(aes(y = chel1 / 10 + 25 , colour = "chel1")) +
  geom_line(aes(y = length, colour = "length")) +
  scale_y_continuous(sec.axis = sec_axis(~ (.- 25) * 10, name = columns_names["chel1"])) +
  scale_colour_manual(values = c("blue", "red")) +
  labs(y = columns_names["length"], x = "Przedział czasowy", colour = "Wartości") +
  theme(legend.position = c(0.25, 0.1)) +
  ggtitle("Długość śledzia wraz z atrubutem chel1 na przestrzeni lat")

ggplot(aggregate_data(completed_data, 1000), aes(x = time_period)) +
  geom_line(aes(y = lcop2 / 10 + 22 , colour = "lcop2")) +
  geom_line(aes(y = length, colour = "length")) +
  scale_y_continuous(sec.axis = sec_axis(~ (.- 22) * 10, name = columns_names["lcop2"])) +
  scale_colour_manual(values = c("blue", "red")) +
  labs(y = columns_names["length"], x = "Przedział czasowy", colour = "Wartości") +
  theme(legend.position = c(0.25, 0.1)) +
  ggtitle("Długość śledzia wraz z atrubutem lcop2 na przestrzeni lat")
```

Wartości cumf i rect wydają się nie mieć wpływu na zmianę długości śledzia na przestrzeni lat. 
```{r}
ggplot(aggregate_data(completed_data, 1000), aes(x = time_period)) +
  geom_line(aes(y = cumf * 100 , colour = "cumf")) +
  geom_line(aes(y = length, colour = "length")) +
  scale_y_continuous(sec.axis = sec_axis(~. / 100, name = columns_names["cumf"])) +
  scale_colour_manual(values = c("blue", "red")) +
  labs(y = columns_names["length"], x = "Przedział czasowy", colour = "Wartości") +
  theme(legend.position = c(0.25, 0.1)) +
  ggtitle("Długość śledzia wraz z rocznym natęzeniem połowów na przestrzeni lat")

ggplot(aggregate_data(completed_data, 1000), aes(x = time_period)) +
  geom_line(aes(y = recr * 0.00005 , colour = "recr")) +
  geom_line(aes(y = length, colour = "length")) +
  scale_y_continuous(sec.axis = sec_axis(~. / 0.00005, name = columns_names["recr"])) +
  scale_colour_manual(values = c("blue", "red")) +
  labs(y = columns_names["length"], x = "Przedział czasowy", colour = "Wartości") +
  theme(legend.position = c(0.25, 0.1)) +
  ggtitle("Długość śledzia wraz z rocznym narybkiem na przestrzeni lat")
```
