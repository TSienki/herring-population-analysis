---
title: "Projekt z analizy danych - analiza długości śledzia oceanicznego wyławianego w Europie."
author: Tomasz Sienkiewicz, Jakub Zdanowski
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
---

# Podsumowanie analizy
Podsumowanie jakieś 

# Wprowadzenie
### Opis problemu
Celem projektu jest określenie głównych przyczyn stopniowego zmniejszania się długości śledzi oceanicznych wyławionych w Europie.

### Opis danych 
Zbiór danych do analizy składa się z pomiarów śledzi i warunków w jakich żyją z ostatnich 60 lat. Dane były pobierane z połowów komercyjnych jednostek. W ramach połowu jednej jednostki losowo wybierano od 50 do 100 sztuk trzyletnich śledzi.

### Opis zmiennych: 

Wszystkie dane, są danymi liczbowymi, nie występują żadne dane kategoryczne.

* __<span style="color:red">length</span>__: długość złowionego śledzia [cm];
* __cfin1__: dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 1];
* __cfin2__: dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 2];
* __chel1__: dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 1];
* __chel2__: dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 2];
* __lcop1__: dostępność planktonu [zagęszczenie widłonogów gat. 1];
* __lcop2__: dostępność planktonu [zagęszczenie widłonogów gat. 2];
* __fbar__: natężenie połowów w regionie [ułamek pozostawionego narybku];
* __recr__: roczny narybek [liczba śledzi];
* __cumf__: łączne roczne natężenie połowów w regionie [ułamek pozostawionego narybku];
* __totaln__: łączna liczba ryb złowionych w ramach połowu [liczba śledzi] - liczba całkowita;
* __sst__: temperatura przy powierzchni wody [°C];
* __sal__: poziom zasolenia wody [Knudsen ppt];
* __xmonth__: miesiąc połowu [numer miesiąca];
* __nao__: oscylacja północnoatlantycka [mb].

### Inicjalizacja środowiska 

```{r results=FALSE}
library(dplyr)
library(ggplot2)
library(GGally) # ggpairplot
library(DT)
library(mice) # for missing data
#ibrary(VIM)
library(ggpubr) # ggarange
library(corrplot) # ggarange
library(plotly)

columns_names <- c("length" = "długość złowionego śledzia [cm]",
  "cfin1" = "dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 1]",
  "cfin2" = "dostępność planktonu [zagęszczenie Calanus finmarchicus gat. 2]",
  "chel1" = "dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 1]",
  "chel2" = "dostępność planktonu [zagęszczenie Calanus helgolandicus gat. 2]",
  "lcop1" = "dostępność planktonu [zagęszczenie widłonogów gat. 1]",
  "lcop2" = "dostępność planktonu [zagęszczenie widłonogów gat. 2]",
  "fbar" = "natężenie połowów w regionie [ułamek pozostawionego narybku]",
  "recr" = "roczny narybek [liczba śledzi]",
  "cumf" = "łączne roczne natężenie połowów w regionie [ułamek pozostawionego narybku]",
  "totaln" = "łączna liczba ryb złowionych w ramach połowu [liczba śledzi]",
  "sst" = "temperatura przy powierzchni wody [°C]",
  "sal"  = "poziom zasolenia wody [Knudsen ppt]",
  "xmonth" = "miesiąc połowu [numer miesiąca]",
  "nao" = "oscylacja północnoatlantycka [mb]" )

prettyTable <- function(table_df, round_columns=numeric(), round_digits=2) {
    DT::datatable(table_df, style="bootstrap", filter = "top", rownames = FALSE, extensions = "Buttons", options = list(dom = 'Bfrtip', buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))) %>%
    formatRound(round_columns, round_digits)
}
```
```{r}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```



# Analiza

### Wczytanie i wstepnę oczyszczenie danych

Pierwszym krokiem jest wczytanie danych oraz bliższe przyjżenie się im. Ponieważ w pliku csv brakujące rekordy zapisane są jako "?" trzeba je poprawnie wczytać.Brakujące dane występują w kolumnach cfin1, cfin2, chel1, chel2, lcop1, lcop2 i lsst. 
Jako że kolumna x to po prostu numer pomiaru, nie będzie nam potrzebna.

```{r}
set.seed(23)
data <- read.csv("sledzie.csv", na.strings = c("?"))
lapply(data, function(x) any(is.na(x)))
data <- subset(data, select = -c(X))

summary(data)
paste0("Ilość badanych przypadków: ", nrow(data), ", ilość zmiennych: ", ncol(data))
head(data, 10)
```
W celu poradzenia sobie z brakującymi danymi zostaje wykorzystana metoda MICE (Multivariate Imputation via Chained Equations). Metoda ta pozwala na pozbycie się brakujących danych z utrzymaniem podobnego rozkład

```{r}
plot_histograms <- function(data, columns=NULL, ncol=1, nrow=1, createName=function(x) x){
  if(is.null(columns)){
    columns <- names(data)
  } 
  
  i <- 1
  plots <- list()
  for (column_name in columns){
    p <- ggplot(data, aes_string(x = column_name)) + 
      geom_histogram(color="black", fill="orange") +
      ggtitle(createName(column_name)) + 
      ylab("Liczba obserwacji")
    plots[[i]] <- p
    i <- i + 1
  }
  figure <- ggarrange(plotlist = plots, ncol = ncol, nrow = nrow)
  # annotate_figure(figure, top = text_grob("dddDDDD"))
  figure
}


  

missing_data_columns <- c("cfin1", "cfin2", "chel1", "chel2", "lcop1", "lcop2", "sst")
plot_histograms(data, columns = missing_data_columns, createName = function(x) paste0("Histogram ", x, " przed pozbyciem się brakujących danych"), nrow=2)
# mice_plot <- aggr(data, col=c('navyblue','yellow'),
#                     numbers=TRUE, sortVars=TRUE,
#                     labels=names(data), cex.axis=.7,
#                     gap=3, ylab=c("Missing data","Pattern"))
completed_data <- data %>%
  mice(m=5,  method = 'cart', seed = 63) %>%
  complete(2)
plot_histograms(completed_data, columns = missing_data_columns, createName = function(x) paste0("Histogram ", x, " po pozbyciu się brakujących danych"), nrow=2)
# Plots could be better, but R is stupid language and I have problem with it. 

```

### Eksploracja danych 

```{r eval=FALSE}
make.assign_year <- function() {
  last_year <- 0
  last_month <- completed_data$xmonth[1]
  
  assign_year <- function(month){
    lm <- last_month
    if(month < last_month){
      last_year <<- last_year + 1
    }
    last_month <<- month
    print(gettextf("%d %d", last_month, lm))
    last_year
  }
  return(assign_year)
}

assign_year <- 

assign_year(8)
assign_year(8)
assign_year(9)
assign_year(1)
assign_year(2)
assign_year(0)
last_month
```

Podsumowanie danych
```{r}
summary(completed_data)
```

Histogramy wartości atrybutów w zbiorze danych 
```{r}
plot_histograms(completed_data, createName = function(x) paste0("Histogram - ", columns_names[x]), nrow=1)

```

Poniżej została przedstawiona korelacja pomiędzy atrybutami.
Można zauważyć, że występuje wysoka korelacja pomiędzy parami atrybutów chel1-lcop1, chel2-lcop2 oraz fbar-cumf. Korelacja może występować, ponieważ, dwie pierwsze pary związane są z dostępnością zaś ostatnia para korelacji może występować, ponieważ obydwa atrybuty związane są z natężeniem popłowu w regionie. Można te pary zredukować, aby przeciwdziałać klątwie wielowymiarowości - jednakże tutaj zostaną one zostawione bez zmian. 

```{r}
corrplot(cor(completed_data), type = "upper",  tl.col = "black", tl.srt = 45, method="number")

ggplot(completed_data, aes(x=chel1, y=lcop1)) + 
  geom_point() + 
  geom_smooth(method=lm) +
  ggtitle("Zależność pomiędzy atrybytem chel1 i lcop1")

linear_model_1 <- lm(chel1 ~ lcop1, data = completed_data)


ggplot(completed_data, aes(x=chel2, y=lcop2)) + 
  geom_point() + 
  geom_smooth(method=lm) +
  ggtitle("Zależność pomiędzy atrybytem chel2 i lcop2")
linear_model_2 <- lm(chel2 ~ lcop2, data = completed_data)


ggplot(completed_data, aes(x=fbar, y=cumf)) + 
  geom_point() + 
  geom_smooth(method=lm) +
  ggtitle("Zależność pomiędzy atrybytem fbar i cumf")
linear_model_3 <- lm(fbar ~ cumf, data = completed_data)

```

Poniżej przedstawiona została analiza długości śledzia na przestrzeni czasu. Jednakże czas nie był przedstawiony jawnie, ale wiadomo, że dane są ustawione chronologicznie dzięki czemu, zbiór można podzielić i na każdym z podziałów policzyć średnią. 
```{r}
cases_per_aggregate <- 200
aggregated_data <- aggregate(completed_data, 
                        list(rep(1:(nrow(completed_data)%/%cases_per_aggregate+1), each=cases_per_aggregate, len=nrow(completed_data))),
                        mean) # Try using mean without outliners
aggregated_data$time_period = c(1:nrow(aggregated_data))
ggplot(aggregated_data, aes(time_period, length)) +
  geom_point() + 
  geom_smooth() +
  ggtitle("Wykres zmiany długości śledzia na przestrzeni czasu") +
  ylab("Długość śledzia") +
  xlab("Przedział czasowy")
```

```{r}
plot_ly(data = aggregated_data, x = ~time_period, y = ~length,
            text = ~paste("Length: ", length)) 
# %>% layout(
#               scene = list(
#                  xaxis = list(title = "Przedział czasowy"),
#                  yaxis = list(title = "Długość śledzia")
#               )
#             )
```
# Wymagania
**Do usunięcia później**
TODO
5. Sekcję podsumowującą rozmiar zbioru i podstawowe statystyki.
9. Sekcję próbującą stworzyć regresor przewidujący rozmiar śledzia (w tej sekcji należy wykorzystać wiedzę z pozostałych punktów oraz wykonać dodatkowe czynności, które mogą poprawić trafność predykcji); dobór parametrów modelu oraz oszacowanie jego skuteczności powinny zostać wykonane za pomocą techniki podziału zbioru na dane uczące, walidujące i testowe; trafność regresji powinna zostać oszacowana na podstawie miar R2 i RMSE.
10. Analizę ważności atrybutów najlepszego znalezionego modelu regresji. Analiza ważności atrybutów powinna stanowić próbę odpowiedzi na pytanie: co sprawia, że rozmiar śledzi zaczął w pewnym momencie maleć.

Done
1. Kod wyliczający wykorzystane biblioteki.
2. Kod zapewniający powtarzalność wyników przy każdym uruchomieniu raportu na tych samych danych.
3. Kod pozwalający wczytać dane z pliku.
4. Kod przetwarzający brakujące dane.
6. Szczegółową analizę wartości atrybutów (np. poprzez prezentację rozkładów wartości).
7. Sekcję sprawdzającą korelacje między zmiennymi; sekcja ta powinna zawierać jakąś formę graficznej prezentacji korelacji.
8. Interaktywny wykres lub animację prezentującą zmianę rozmiaru śledzi w czasie.
